"""
2021.02.24
Andrew Ng - Deep Learning
Chater 3. Structuring Machine Learning Projects
Week 2. ML Strategy(2)

"""


"""
1. Carrying out error analysis
고양이 분류기에서 90퍼센트의 정확도를 획득했다고 해보자.
성능을 더 높이기위해, 틀리게 분류한 사진들을 카테고리화 해보면
고양이와 비슷한 강아지의 사진 등이 모일 것이다.
이 강아지 사진들에 대해 더 잘 작동하게 하기 위해 알고리즘을 강화해본다면
과연 그 작업이 전체 트레이닝 세트의 성능을 높여주는데 큰 도움을 줄까 ?
NO. 잘못 분류된 100개의 샘플 중 강아지 사진이 5개라면
10%의 에러에서 0.5% 정도만 향상시킬 수 있다.  ->  비효율적일 수 있다.
그러나 강아지 문제에 대한 상한선은 제시할 수 있을 것이다.(ceiling on performance)
만약 잘못 분류된 100개의 샘플 중 강아지 사진이 50개라면 효율적일 것이다.

고양이 분류기의 성능을 향상시키기 위해서는
  1) 강아지 성능 향상
  2) 사자, 표범, 치타 등 great cat 성능 향상
  3) 흐린 이미지에서 잘 작동하는 알고리즘 성능 향상
잘못 분류된 이미지들을 위의 세 가지로 다시 분류하여 %를 계산한 뒤
가장 효율적인 방법을 찾는다.






2. Cleaning up incorrectly labeled data
만약 학습 알고리즘이 틀린 y값을 줄때는 어떻게 해야할까 ?
= 만약 틀리게 레이블된 샘플이 있다면 어떻게 해야할까 ?

만약 그 레이블이 비교적 랜덤하다면, 그대로 놔둬도 괜찮다.
딥러닝 알고리즘은 랜덤 오류에 강하다. systemic 에러에는 약하다.

그렇다면 dev 세트에서 이와 같은 오류가 발생했다면 ?
전체 dev set의 에러 - 10%
틀린 레이블 때문에 발생한 에러 - 0.6%
기타 다른 이유로 발생한 에러 - 9.4% 일 때,
틀린 레이블을 고치는 것은 비효율적일 수 있다.

전체 dev set의 에러 - 2%
틀린 레이블 때문에 발생한 에러 - 0.6%
기타 다른 이유로 발생한 에러 - 1.4% 라면
틀린 레이블을 고쳐야할 것이다.






3. Build your first system quickly, then iterate
음성인식 시스템에서 신경써야할 과제들은
  1) 시끄러운 주변 환경 - 카페 소음, 차 소음
  2) 특정한 억양
  3) 마이크에서 떨어져 있을 때
  4) 어린 아이들의 말(낱말의 조합, 발음) 
  5) 아, 음 등의 의미없는 문구 
등이 있다.

만약 완전히 새로운 러닝 어플리케이션을 만든다면
시스템을 빨리 만들고, 반복 테스트를 진행하는 것이 좋다.
  1) dev/test set와 그 메트릭을 셋업한다.   ->  목표 설정
  2) 머신러닝 시스템 만들기
  3) 바이어스/편차 분석, 오류 분석을 진행
  4) 3단계의 결과값으로 다음 단계의 우선순위 결정






4. Training and testing on different distributions
웹페이지의 고양이 사진으로 학습한 고양이 분류기 어플이 있을 때 
사용자들이 직접 찍은 사진(아마추어적, 희미, 덜 프레임됨)으로 인식해보자.
그 개수는 웹 : 200,000 vs 사용자 : 10,000개 라고 한다면
그 둘을 합친 210,000개의 이미지를 임의로 섞어 학습하고
dev/test 세트를 거쳤다. (각각 2500개)
이 때 장점은 train/dev/test가 모두 같은 분포도를 가지고 관리하기 쉽다는 것이다.
단점은 2500개의 dev 세트 중 대부분이 웹에서 온 사진이라는 것이다.

대신, train 세트에 웹에서 온 20만개 + app에서 온 5000를 주고
dev/test 세트에 각각 app에서 온 사진을 2500개 씩 주어 학습해보자.
단점은 train세트가 dev/test세트의 분포와 다르다는 것이지만
목표(app에서 온 사진)가 확실히 설정되는 장점이 있다.






5. Bias and Variance with mismatched data distributions
인간 성능 error - 거의 0%
train error- 1%
dev error - 10% 일 때,
편차가 크다고 볼 수도 있지만,
트레이닝 세트에서는 비교적 쉬운 샘플들로 이루어져 쉽고
dev 세트에서는 훨씬 어려웠을 수 있다.

따라서 이 경우에는 training-dev set라는 새로운 데이터 집합을 정의하고
트레이닝 세트에서 일부 추출하여 테스트한다.(동일한 분포도 가짐)
그 때의 오류가 트레이닝 세트의 오류보다 현저히 크다면
알고리즘이 잘 일반화되지 않는다는 것을 알 수 있을 것이다.
만약 그 오류가 트레이닝 세트의 오류와 비슷하고 dev set와는 현저히 차이난다면
전형적인 데이터 미스매치 문제가 발생했다는 것을 알 수 있다.

+) 
학습 알고리즘에서 편향과 분산을 예측하는 것은 일의 순서를 정하기 위해 필요하다.
그러나 그 예측법은 train과 dev가 다른 분포도를 가진다면 달라진다.

In Cat Classifier, 인간성능이 0% error에 가깝다고 해보자.
그렇다면 bayes error도 거의 0%일 것이다.
train error - 1%
dev error - 10% 이고 둘의 분포도가 같다면 분산에 대한 문제가 있을 것이다.
그러나 둘의 분포도가 다르다면,
1) 분산의 문제일 수도 있고
2) train에서는 쉬운 샘플들이 있고 dev에선 급격히 어려워진 것일 수도 있다.
이 두 문제를 구분하기 위해서 training-dev set이라는 데이터들의 새로운 부분집합을 다뤄보자.
이것은 훈련세트와는 같은 분포를 가지지만 학습에는 사용되지 않은 것이다.

이 때, train error - 1%, train-dev error - 9%, dev error - 10%이다.
train과 train-dev는 같은 분포이기때문에 이것은 분산의 문제가 있다는 것을 알려준다.

train error - 1%, train-dev error - 1.5%, dev error - 10% 라면
데이터 불일치의 문제가 있다는 것을 알려준다.
따라서 알고리즘이 분포가 다른 데이터에서도 잘 작동할 수 있게 해줘야 한다.

그러나 train error - 10%, train-dev error - 11%, dev error - 12% 라면
베이지안 오차는 0%에 가깝기 때문에
편향 문제 또는 avoidable bias 문제가 있을 것이다.

train error - 10%, train-dev error - 11%, dev error - 20% 라면
avoidable bias 문제와 데이터 불일치 문제가 동시에 있다고 볼 수 있다.

따라서
인간 성능 오류
-> avoidable error
train error
-> variance
train-dev error
-> data mismatch
dev error
-> degree of overfit (과적합의 정도)
test error






6. Addressing data mismatch
데이터 불일치 문제가 발생했을 때, 해결방법은 무엇일까 ?
오차분석을 수행하여 훈련세트와 dev/test 세트의 차이가 무엇인지 알아본다.
만약 dev 세트가 훈련세트보다 현저하게 어렵다면 훈련 데이터를 비슷하게 만들어야한다.
-> 인공적으로 데이터를 합성해보자.

In 음성인식,
깔끔하게 녹음된 "The quick brown fox jumps over the lazy dog" 파일과
자동차의 소음을 합성하면 시끄러운 차 안에서 말하는 것과 비슷해질 것이다.
이런 식으로 인공적 데이터 합성을 통해 빠르게 많은 데이터를 만들 수 있다.
주의점은, 10000시간의 음성 녹음과 1시간의 차 소음의 데이터가 있다면
학습 알고리즘에 1시간 길이의 차 소음이 과적합될 수 있다는 것이다.






7. Transfer Learning
전이학습이란 ?
신경망을 이미지 인식에 대해서 학습시켰다고 해보자.
(x, y)에서 x는 이미지이고 y는 이미지 안의 어떤 물체(고양이, 개, 새 등)를 의미한다.
이 신경망을 사용하여 x-ray 사진을 판단하도록 전이시켜보자.
먼저 신경망의 마지막 출력층을 삭제하고 임의로 초기화된 출력을 만들고
새로운 x에 x-ray사진을, y에 진단명을 의미하도록 교체한 뒤 학습시킨다.
데이터 세트가 작다면 마지막 한 두개의 층만 재훈련하고,
충분히 큰 데이터 세트가 있다면 신경망의 모든 변수를 재훈련한다.

A에서 B로의 전이학습을 한다고 가정한다면,
성공적인 B의 결과를 얻기 위해서는
B보다 A의 데이터가 많을 때 잘 적용된다.
또, A의 low level 특성들이 B를 학습하는데 도움이 될 때 잘 적용된다.






8. Multi-task learning
멀티태스킹은 한 신경망이 여러 작업을 동시에 할 수 있도록 하고
각 작업들은 다른 나머지 작업들에게 도움을 준다.

자율주행 자동차에서 감지하는 것들은,
pedestrians
other cars
stop signs
traffic lights 이고 (감지하면 1, 없으면 0)
하나의 입력 샘플 x인 사진은 총 네개의 y 레이블을 가지게 된다. (y는 (4, 1) 벡터)
Y = [y1, y2, y3, y4]이고 각각의 y는 (4, 1)이니 (4, m)차원의 행렬이 된다.
(4, 1) 차원의 y^(yhat)이 주어졌을 때 손실값은 전체 훈련세트에 대한 평균이 되고
L값은 일반적인 로지스틱 손실이 된다.

네 개의 문제를 해결하기 위해 분리된 네 개의 신경망을 훈련하는 것 보다,
신경망의 초기 특성들은 여러 물체에 대해 공유될수 있기 때문에
네 개의 물체에 대해 하나의 신경망을 훈하는 것이 더 효율적이다.

멀티태스크 작업은
1) 하나의 lowlevel 특성을 공유할 때 이익이 되는 작업을 학습하는 경우
2) 각 작업이 가지는 데이터의 양이 비슷한 경우
3) 모든 작업에 대해 충분히 큰 신경망을 훈련할 수 있는 경우
사용하는 것이 좋다.






9. What is end-to-end deep learning ?
In Speech recognition example,
입력값 x는 녹음파일이고 출력값 y는 녹음파일의 대본이라고 해보자.
전통적으로 음성인식은 여러개의 처리 단계를 요구한다.
1) 녹음파일의 특징 추출(MFCC)
2) ML 알고리즘을 이용해 녹음파일의 음소 찾아내기
3) 단어들을 조합하여 대본 만들기
endtoend 딥러닝은 이런 파이프라인을 거치지 않고 바로 진행되게끔 만들 수 있다.
한계점은, 사전에 많은 정보가 필요하다는 것이다.
작은 데이터 집합일수록 기존의 파이프라인이 잘 작동할 것이다.






10. Whether to use end-to-end deep learning ?
end-to-end의 장점 ?
- 데이터가 직접 나타나게 해준다.(데이터 그 자체의 의미, 사람의 선입견 X)
- 중간 요소의 설계를 적게해도 된다.(작업의 단순화)

단점 ?
- 많은 양의 데이터가 필요하다.
- 사람의 손으로 만들어진 잠재적으로 유용한 요소들을 배제한다.

end-to-end 알고리즘의 키포인트는, 충분한 데이터를 가지고 있느냐이다.









"""